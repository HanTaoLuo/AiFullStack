


!pip install "pymilvus[model]==2.5.10" openai==1.82.0 requests==2.32.3 tqdm==4.67.1 torch==2.7.0








#glob库是Python标准库中用于文件路径匹配的模块，支持通配符模式查找文件 支持递归查找
from glob import glob
text_line = []
file_regex_path = "../rag_resources/milvus_docs/en/faq/*.md"
for file_path in glob(file_regex_path,recursive=True):
    with open(file_path,"r") as f:
        file_text = f.read()
    text_line+=file_text.split("# ")
print(text_line)


import os
deepseek_key = os.getenv("DEEPSEEK_API_KEY")



# 准备 LLM 和 Embeding 模型
from openai import OpenAI

deepseek_api_base_address="https://api.deepseek.com/v1"

deepseek_client = OpenAI(
    api_key=deepseek_key,
    base_url=deepseek_api_base_address
)



# 定义 embedding 模型 ，使用 milvus_model 做文本嵌入(embedding)  默认使用 DefaultEmbeddingfunction 为例， 这是一个预训练的轻量embedding 模型
from pymilvus import model as milvus_model
# 嵌入方法
embedding_model = milvus_model.DefaultEmbeddingFunction()


test_question_list = ["This is test question"]
# 结果数组为二维数组  第一维的大小与问题个数有关  如果只有一个问题那么第一维大小只有 1  其中第一维度长度只有 1 ，第二维度为高维向量
embedding_arr = embedding_model.encode_queries(test_question_list)
embedding_vector = embedding_arr[0]
embedding_dim = len(embedding_vector)
# 向量维度(768维)
print(embedding_dim)
# 打印向量前 10 个元素
print(embedding_vector[:10])





# 创建collection  collection 等同于关系型数据库表的概念
from pymilvus import MilvusClient
local_save_file = "./milvus_demo.db"
collection_name = "test_rag_collection1"
milvus_client = MilvusClient(uri=local_save_file)
if milvus_client.has_collection(collection_name):
    milvus_client.drop_collection(collection_name)







metric_type="IP"
consistency_level = "Strong"
milvus_client.create_collection(
    collection_name=collection_name,
    #向量维度 与问题个数无关，只有单个向量的维度有关 bert 模型向量维度 768
    dimension=embedding_dim,
    # 计算向量相似度方法
    metric_type=metric_type,
    consistency_level=consistency_level
)






# tqdm 为一个可视化的进度条模块
from tqdm import tqdm
# 定义插入到 milvus 中的数据列表
data = []
#调用模型 encode_document 将数据encode 成 vector
# text_line 中为二维数组，对应第一维 为文本块个数，第二维 为每个文本块映射的 768 维向量
doc_embeddings =embedding_model.encode_documents(text_line)
text_line_size =  len(text_line)
print(f"文本块个数为: {text_line_size}")
print(f"二维数组 第一维 大小为 :{len(doc_embeddings)}")
# enumerate() 是 Python 中的一个内置函数，它用于将一个可遍历的数据对象（如列表、元组或字符串）组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中
for index,line in enumerate(tqdm(text_line,desc="create embeddings!")):
    item={"id":index,"vector":doc_embeddings[index],"text":line}
    data.append(item)
milvus_client.insert(collection_name=collection_name,data=data)






question = "How is data stored in milvus?"





# 将问题转换为嵌入向量
question_embedding_vector = embedding_model.encode_queries([question])
# 查询参数包含 搜索方式  搜索方式和文档写入 milvus 的方式要保持一致 否则会搜索不精准
search_params={"metric_type":"IP","params":{}}
# milvus 返回的字段
output_fields  = ["text"]
search_result = milvus_client.search(
    collection_name=collection_name,
    # data 指的是 query 的问题 vector
    data=question_embedding_vector,
    limit=3, # 返回前 3 个 结果,
    search_params=search_params,
    output_fields=output_fields
)



import json
# search_result为 返回 search 到的所有结果，结果为二维数组   第一维只有一个元素。

print(len(search_result))

retrieved_lines_with_distince = [
    (res['entity']["text"],res["distance"]) for res in search_result[0]
]
# indent：指定缩进的空格数或字符串，用于结构化显示JSON数据
print(json.dumps(retrieved_lines_with_distince,indent=4))





### 使用LLM获取RAG响应
将检索到的文档转换为字符串格式


context_str = "\n".join(
    [line[0] for line in retrieved_lines_with_distince]
)
context_str


question





SYSTEM_PROMPT="""
Human : 你是一个 AI 助手、你能从提供的上下文段落片段中和你的知识储备中找到问题的答案
"""

USER_PROMPT=f"""
请使用以下用<milvus-search> </milvus-search> 标签括起来的信息片段来回答<question> </question> 标签括起来的问题，最后追加原始回答的中文翻译,并用<translate> 和</translate>进行标记
<milvus-search>{context_str} </milvus-search>
<question>{question}</question>
<translate></translate>
"""


USER_PROMPT





deepseek_model_type = "deepseek-chat"
messages= [
    {"role":"system","content":SYSTEM_PROMPT},
    {"role":"user","content":USER_PROMPT}
]
# chat 表示聊天模型,completions 表示补全
response = deepseek_client.chat.completions.create(
    model= deepseek_model_type,
    messages=messages
)
print(response.choices[0].message.content)



